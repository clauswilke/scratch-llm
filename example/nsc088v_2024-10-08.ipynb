{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4efec1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from model.llm import LLM\n",
    "from model.tokenizer import Tokenizer, train_tokenizer\n",
    "\n",
    "from helpers.dataset import NextTokenPredictionDataset\n",
    "from helpers.trainer import train\n",
    "from helpers.config import LLMConfig, TrainingConfig, get_device\n",
    "\n",
    "print(f\"pytorch version: {torch.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc5b1f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_config = LLMConfig(\n",
    "    vocab_size = 4096,\n",
    "    seq_len = 128,\n",
    "    dim_emb = 256,\n",
    "    num_layers = 4,\n",
    "    num_heads = 8,\n",
    "    emb_dropout = 0.0,\n",
    "    ffn_dim_hidden = 4 * 256,\n",
    "    ffn_bias = False\n",
    ")\n",
    "train_config = TrainingConfig(\n",
    "    retrain_tokenizer = False,\n",
    "    device = get_device(),\n",
    "    batch_size = 64,\n",
    "    learning_rate = 3e-4,\n",
    "    weight_decay = 1e-5,\n",
    "    max_epochs = 1,\n",
    "    log_frequency = 1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f705c1ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = \"../data/tinyshakespeare.txt\"\n",
    "output_file = Path(input_file).with_suffix(\".model\")\n",
    "\n",
    "if not output_file.exists() or train_config.retrain_tokenizer:\n",
    "    train_tokenizer(input_file, llm_config.vocab_size)\n",
    "\n",
    "tokenizer = Tokenizer(str(output_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5fcd440",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"Before we proceed any further, hear me speak. Acquaintances. Dog Dogs. ance\"\n",
    "print(tokenizer.sp.EncodeAsPieces(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5222b6a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train = NextTokenPredictionDataset(input_file, llm_config.seq_len, tokenizer)\n",
    "dl_train = DataLoader(ds_train, batch_size=train_config.batch_size, shuffle=True)\n",
    "##\n",
    "for inputs, labels in dl_train:\n",
    "    print(inputs.shape, labels.shape)\n",
    "    break\n",
    "\n",
    "device = get_device()\n",
    "model = LLM(\n",
    "    vocab_size = tokenizer.vocab_size,\n",
    "    seq_len = llm_config.seq_len,\n",
    "    dim_emb = llm_config.dim_emb,\n",
    "    num_layers = llm_config.num_layers,\n",
    "    attn_num_heads = llm_config.num_heads,\n",
    "    emb_dropout = llm_config.emb_dropout,\n",
    "    ffn_hidden_dim = llm_config.ffn_dim_hidden,\n",
    "    ffn_bias = llm_config.ffn_bias\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d25d7dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss_history = train(\n",
    "#     model,\n",
    "#     dl_train,\n",
    "#     train_config.device,\n",
    "#     lr = train_config.learning_rate,\n",
    "#     max_epochs = train_config.max_epochs,\n",
    "#     weight_decay = train_config.weight_decay,\n",
    "#     log_every = train_config.log_frequency\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8bcf2e5",
   "metadata": {},
   "source": [
    "Un-comment block above to train model (takes a few minutes on the AMD GPU cluster) **or** just use pre-trained model using block below (must upload this to your home directory for this work):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc92994",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(device)\n",
    "model.load_state_dict(torch.load(\"shakespeare_llm.pt\",\n",
    "                                 weights_only = True,\n",
    "                                 map_location = device))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ffb9b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# empty prompt to generate random stuff\n",
    "prompt = torch.full((1, llm_config.seq_len), tokenizer.eos_id, dtype=torch.int32)\n",
    "prompt = prompt.to(train_config.device)\n",
    "out = model.generate(prompt, max_seq_len=64, top_p=1)\n",
    "tokenizer.decode(out.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5712047b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate from a prompt\n",
    "prompt = tokenizer.encode(\n",
    "    \"KING HENRY VI:\",\n",
    "    beg_of_string = True,\n",
    "    pad_seq = True,\n",
    "    seq_len = llm_config.seq_len\n",
    ")\n",
    "inputs = torch.tensor(prompt, dtype=torch.int32).unsqueeze(0).to(train_config.device)\n",
    "out = model.generate(inputs, max_seq_len=64, top_p=1, temperature=1000)\n",
    "tokenizer.decode(out.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211a4661",
   "metadata": {},
   "outputs": [],
   "source": [
    "parList = list(model.parameters())\n",
    "len(parList) ## 35\n",
    "parShapes = [list(el.shape) for el in parList]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77deb70a",
   "metadata": {},
   "source": [
    "parameters consist of:\n",
    "\n",
    "- **0** :: weight matrix for **token embeddings**\n",
    "\n",
    "<!-- -->\n",
    "\n",
    "- **1** :: **RMSNorm** parameter vector\n",
    "- **2** :: Q, K, V matrices (concatenated) for **MultiHeadAttention**\n",
    "- **3** :: weight matrix for projout part of **MultiHeadAttention**\n",
    "- **4** :: **RMSNorm** parameter vector\n",
    "- **5** :: initial weight matrix for **FeedForward (SwiGLU)** part\n",
    "- **6** :: **SwiGLU** weight matrices (concatened)\n",
    "- **7** :: **SwiGLU** bias vector\n",
    "- **8** :: final weight matrix for **FeedForward (SwiGLU)** part\n",
    "\n",
    "<!-- -->\n",
    "\n",
    "-  **9-16** :: as 1-8 but for second TransformerBlock\n",
    "- **17-24** ::        \"       third         \"\n",
    "- **25-32** ::        \"       fourth        \"\n",
    "\n",
    "<!-- -->\n",
    "\n",
    "- **33** :: **RMSNorm** parameter vector\n",
    "- **34** :: final **projection_head** bias vector\n",
    "\n",
    "**NOTE**: there is no weight matrix for the final projection head b/c it is \"weight-tied\" to the token embeddings weight matrix (0 above)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c3c295",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "tokens = np.array([tokenizer.sp.id_to_piece(i)\n",
    "                   for i in range(llm_config.vocab_size)])\n",
    "\n",
    "tokenizer.sp.piece_to_id(\"▁perforce\")\n",
    "tokenizer.sp.piece_to_id(\"▁basilisk\")\n",
    "\n",
    "emb = pd.DataFrame(parList[0].cpu().detach(), index=tokens)\n",
    "emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "893a8787",
   "metadata": {},
   "outputs": [],
   "source": [
    "activation = {}\n",
    "def get_activation(name):\n",
    "    def hook(model, input, output):\n",
    "        activation[name] = output.detach()\n",
    "    return hook\n",
    "\n",
    "model.token_embedding.register_forward_hook(get_activation('token_embedding'))\n",
    "model.transformer[0].norm_attn.register_forward_hook(get_activation('rmsnorm0'))\n",
    "model.transformer[0].multihead_attn.register_forward_hook(get_activation('mha0'))\n",
    "model.transformer.register_forward_hook(get_activation('transformer'))\n",
    "output = model(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d5f6e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "promptN = tokenizer.encode(\n",
    "    \"Such an act\",\n",
    "    beg_of_string = True,\n",
    "    pad_seq = True,\n",
    "    seq_len = llm_config.seq_len\n",
    ")\n",
    "inputsN = torch.tensor(promptN, dtype=torch.int32).unsqueeze(0).to(train_config.device)\n",
    "outputN = model(inputsN)\n",
    "en = activation['token_embedding'][0, 127, :].cpu().detach().numpy()\n",
    "tn = activation['transformer'][0, 127, :].cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdff6ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotnine as gg; gg.theme_set(gg.theme_bw())\n",
    "gg.qplot(en, tn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e7d7880",
   "metadata": {},
   "outputs": [],
   "source": [
    "promptV = tokenizer.encode(\n",
    "    \"I have act\",\n",
    "    beg_of_string = True,\n",
    "    pad_seq = True,\n",
    "    seq_len = llm_config.seq_len\n",
    ")\n",
    "inputsV = torch.tensor(promptV, dtype=torch.int32).unsqueeze(0).to(train_config.device)\n",
    "outputV = model(inputsV)\n",
    "ev = activation['token_embedding'][0, 127, :].cpu().detach().numpy()\n",
    "tv = activation['transformer'][0, 127, :].cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c436357e",
   "metadata": {},
   "outputs": [],
   "source": [
    "gg.qplot(en, ev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02302911",
   "metadata": {},
   "outputs": [],
   "source": [
    "gg.qplot(tn, tv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "185643bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def nextTokenProbs(inputString, temperature=0.6):\n",
    "    prompt = tokenizer.encode(inputString,\n",
    "                              beg_of_string = True,\n",
    "                              pad_seq = True,\n",
    "                              seq_len = llm_config.seq_len)\n",
    "    inputs = torch.tensor(prompt, dtype=torch.int32)\\\n",
    "                  .unsqueeze(0)\\\n",
    "                  .to(train_config.device)\n",
    "    logits = model(inputs)[:, -1, :]                 ## (bs, vocab_size)\n",
    "    probs = F.softmax(logits / temperature, dim=-1)  ## (bs, vocab_size)\n",
    "    return pd.Series(probs.cpu().detach().numpy()[0, :], index=tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa78516f",
   "metadata": {},
   "outputs": [],
   "source": [
    "nextTokenProbs(\"Such an act\").sort_values().tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e37de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "nextTokenProbs(\"I have act\").sort_values().tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed4e37f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mha0 = model.transformer[0].multihead_attn\n",
    "qkv = mha0.proj_qkv(activation['rmsnorm0'])\n",
    "\n",
    "q, k, v = qkv.chunk(3, dim=-1)\n",
    "# (bs, seq_len, dim_k), (bs, seq_len, dim_k), (bs, seq_len, dim_v)\n",
    "\n",
    "# split projections between heads -> (bs, num_heads, seq_len, dim_k/dim_v):\n",
    "q = q.view(-1, mha0.seq_len, mha0.num_heads, mha0.dim_head).permute(0, 2, 1, 3)\n",
    "k = k.view(-1, mha0.seq_len, mha0.num_heads, mha0.dim_head).permute(0, 2, 1, 3)\n",
    "v = v.view(-1, mha0.seq_len, mha0.num_heads, mha0.dim_head).permute(0, 2, 1, 3)\n",
    "\n",
    "q = mha0.positional_encoding(q)  # (bs, num_heads, seq_len, dim_k)\n",
    "k = mha0.positional_encoding(k)  # (bs, num_heads, seq_len, dim_k)\n",
    "\n",
    "attn_scores = (q @ k.permute(0, 1, 3, 2)) * mha0.dim_k**-0.5\n",
    "\n",
    "attn_scores.masked_fill_(mha0.causal_mask[None, None, ...], -torch.inf)\n",
    "\n",
    "# attention scores are used to build a weighted linear combination of values vectors:\n",
    "attn_scores = torch.softmax(attn_scores, dim=-1)\n",
    "out = attn_scores @ v\n",
    "\n",
    "# merge heads:\n",
    "out = out.permute(0, 2, 1, 3).contiguous().view(-1, mha0.seq_len, mha0.dim_v)\n",
    "# project to output space:\n",
    "out = mha0.proj_out(out)\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebcd2664",
   "metadata": {},
   "outputs": [],
   "source": [
    "activation['mha0']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
